# Function Caching

It would be very nice to be able to run some functions in the cog without starting a new cog (when running in hub mode). To do this in the most flexible way, we'll use the cog RAM as a function cache and mark those functions that should be cached with the "cogtext" attribute (maybe change it to "fcache"?). When calling a cogtext function, we'll set up for a complete function call as usual, but instead of calling the function, we'll place the address of the function into `pa`, the size of the function into `pb` and call an intermediate function that will 
1. look to see if this function is loaded into the function cache
2. if so, call it
3. if not, load it into the cache and then call it. 

This function cache loader function should live in LUT ram just like any other runtime library function (if it will fit... might need to write it in assembly directly?). 

How the function cache will operate: 
1. maintain a map of hub addresses -> (cog addresses, size in cog ram) to know where things are in the cache
2. on entry to our cache loading function, check if the hub address is in our map
3. if it is: cache hit: read the corresponding cog address and call it. 
4. if it is not: cache miss: get the next free cog address (need to keep adding up sizes as we search the cache), use a rdfast to load the desired address into that free cog address (assuming there's enough space). Call it. If not enough space to load, go back to the begining of the cache and overwrite that function and any hub addresses it affects in the cache map

Implementation phases: 
1. maintain a 1-entry cache map. That is, every time a new function is desired, it must be loaded and the old one discarded. 
2. expand the map to 464 entries (one for every possible cog address in it's worst case where every function is just a `reta`). Load functions one after another, ignoring what happens when you run out of space
3. handle running out of space by looping around the cache.

One thing to decide still: should we use fixed size slots and just track what the slot contains? Might make implementation simpler but reduces flexibility. 

Cache map organization:
- each entry is 4 hub longs in size.
- store in somewhere in BSS so it's cleared on boot
- long 0 is the key: a non-zero value is a hub address, a 0 is an empty entry, and a -1 (0xffffffff) is a special value we'll use in the future
- long 1 is the corresponding 9 bit cog address where this function has been loaded
- long 2 is the size of the function in longs. 
- long 3 is reserved for future use

Testing:
- Develop a set of functions with a lot of branches (the main reason to cache these functions) and some that use the streamer
- time how long it takes to run the functions with and without caching
- make sure the streamer works. 

## Re-exambining on Jan 9, 2024

One possible pitfall is when a cached function calls another and we run out of slots and then we overwrite the original function code, breaking things. 
Also, getting the size of the function in LLVM isn't trivial given my knowledge. So instead we will have fixed size cache slots that we'll load code into. 

At the end of each cache slot we'll have a jump back to a routine in the cacher that will load the next block of code. If the cache slot contains the end of the function, 
it's `reta` command will exit the cache and execution will continue

In this mode, we just need to track which block of code by address is in each cache slot. 

### Here's the basic plan:
- we create a new attribute called `cogcache`. 
- in call lowering, if the destination is marked with this attribute, insert the following instructions:
    - move the call destintation to pa `mov pa, DST`
    - call to cog address 0 (where our cacher function will live) `calla #0` (this sets the return properly when the cached function reaches it's `reta`)
- the cacher will be written in pure assembly as use our hex based registerng to not touch r0-r31. 
- the cacher needs to do the following
    - check if the value in PA is in the cache. If it is, jump to that cache slot
    - if it's not, use the fifo/rdfast to fill the cache slot, then jump to it

### Sizing
- lets assume we need ~50 instructions for the cacher. 463 is the last address we can use. Assume we want 8 even slots (8 is arbitrary). Make the slot 50 instructions long,
  leaving 63 instructions for the cacher. 32 of these is for the table. 50 instructions allows for a small function to be cached in whole. might need to make the slots smaller.
  The last line in the slot must always be and jmp to the "continue" subroutine of the cacher

### Determining cache hits/misses
- we need a hash function to convert the 20 bit address to a value between 0-7 (for the 8 slots)
    - is unique hashing possible here? we don't want to map to the same slot for 2 different pieces of code
    - or, we check that the contents of the slot are as intended. not sure if a simple search through the slot table is faster or doing a hash, reading that offset, and checking
      that the slot address is what we wanted. let's assume we won't do a simple search
- Use the hash function to compute a key in 0-7. Check that the key in the slot is the same as pa--if it is, we have a cache hit. if it's 0, we can use this slot. otherwise, 
  we'll be replacing this slot. 
- if we have a cache hit, jump to the slot 
- if we have a miss, start the fifo and rdfast the slot. 

### Continue subroutine
- if the function isn't complete by the end of the slot, we'll jump to a continue subroutine. that routine needs to add to slot address the size of the slot, and run the whole thing again

### Cache recurrance
Lets say our cached function calls another cached function. This will cause the cache to start loading that block of code. the calla will store the return address that's in the cogspace. 
Let's say that the new function being loaded now overwrite the slot. when it tries to return, it'll return to the now-overwritten cach slot, which breaks. One solution is to mark the slot as
"in use" so if we have a collision, we just go to the function directly instead of loading it to the cache. But, there's no way to clear the in-use since there's no exit routine before we 
leave the cog. we could in theory modify the stack on entry to the cacher to change the return address to an exit routine, which will then jump back.

### Function recurrance
Lets say the cached function calls itself. The cacher entry will overwrite the return address on the stack and continue. however, it needs to save this address as well. but that will overwrite the previously saved address. Solution for now would be not allow entry into an "in use" slot even if it's the same code. longer term is a necessity to use a stack to store these values. using the local stack limits us to 8 calls and then we need to check for overflows. 

All these considered, here's the algorithm for the cache system

*Compiler*
1. If a function is marked as `cogcache`, set the destination to pa and call to address 0. 
2. that's it? We won't want to modify the return because we don't gaurantee that the function will be cached. 

*Cacher*

Cache map organization
- each entry is 2 hub longs in size.
- store in somewhere in BSS so it's cleared on boot
- long 0 is the key: a non-zero value is a hub address, a 0 is an empty entry, and a -1 (0xffffffff) is a special value we'll use in the future
    - if MSB is set (and the value is not -1), then this slot is considered "in use" and it should not be overwritten. 
- long 1 is the corresponding 9 bit cog address where this function has been loaded 


1. Hash the address stored in pa. 
    - hash algorithm:
2. Read the key from the corresponding hash slot.
    - if it is equal and not in use, mark the slot as in use (make MSB of the key = 1)
    - if it's not equal and not in use, load the code using rdfast and rflong
    - if the slot is in use, we can't populate it yet, so just jump to the address at pa
3. Mark the slot as in use and set up the jump
    - the top of our stack is set up to return to the caller. modify the lower 20 bits to instead point to the exit routine and save the original value. 
    - jump to the cache slot.
4. Exit routine: if we hit a `reta` in the cache slot, it will jump to this exit routine
    - in the exit routine, mark the slot as no longer in use, jump to the true return address. 